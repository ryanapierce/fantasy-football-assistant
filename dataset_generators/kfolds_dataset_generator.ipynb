{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7aae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5ba82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the original or main dataset\n",
    "orig_df = pd.read_csv('./datasets/final_1_lag_ffa_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9db8f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['player_id', 'player_name', 'player_display_name', 'position',\n",
       "       'position_group', 'headshot_url', 'season', 'week', 'season_type',\n",
       "       'team', 'opponent_team', 'age', 'years_exp',\n",
       "       'passing_yards_r_avg_1_lag_1', 'passing_yards_r_avg_3_lag_1',\n",
       "       'passing_yards_r_avg_5_lag_1', 'passing_yards_r_avg_8_lag_1',\n",
       "       'passing_tds_r_avg_1_lag_1', 'passing_tds_r_avg_3_lag_1',\n",
       "       'passing_tds_r_avg_5_lag_1', 'passing_tds_r_avg_8_lag_1',\n",
       "       'passing_interceptions_r_avg_1_lag_1',\n",
       "       'passing_interceptions_r_avg_3_lag_1',\n",
       "       'passing_interceptions_r_avg_5_lag_1',\n",
       "       'passing_interceptions_r_avg_8_lag_1',\n",
       "       'passing_2pt_conversions_r_avg_1_lag_1',\n",
       "       'passing_2pt_conversions_r_avg_3_lag_1',\n",
       "       'passing_2pt_conversions_r_avg_5_lag_1',\n",
       "       'passing_2pt_conversions_r_avg_8_lag_1',\n",
       "       'sack_fumbles_lost_r_avg_1_lag_1', 'sack_fumbles_lost_r_avg_3_lag_1',\n",
       "       'sack_fumbles_lost_r_avg_5_lag_1', 'sack_fumbles_lost_r_avg_8_lag_1',\n",
       "       'rushing_yards_r_avg_1_lag_1', 'rushing_yards_r_avg_3_lag_1',\n",
       "       'rushing_yards_r_avg_5_lag_1', 'rushing_yards_r_avg_8_lag_1',\n",
       "       'rushing_tds_r_avg_1_lag_1', 'rushing_tds_r_avg_3_lag_1',\n",
       "       'rushing_tds_r_avg_5_lag_1', 'rushing_tds_r_avg_8_lag_1',\n",
       "       'rushing_fumbles_lost_r_avg_1_lag_1',\n",
       "       'rushing_fumbles_lost_r_avg_3_lag_1',\n",
       "       'rushing_fumbles_lost_r_avg_5_lag_1',\n",
       "       'rushing_fumbles_lost_r_avg_8_lag_1',\n",
       "       'rushing_2pt_conversions_r_avg_1_lag_1',\n",
       "       'rushing_2pt_conversions_r_avg_3_lag_1',\n",
       "       'rushing_2pt_conversions_r_avg_5_lag_1',\n",
       "       'rushing_2pt_conversions_r_avg_8_lag_1',\n",
       "       'receiving_yards_r_avg_1_lag_1', 'receiving_yards_r_avg_3_lag_1',\n",
       "       'receiving_yards_r_avg_5_lag_1', 'receiving_yards_r_avg_8_lag_1',\n",
       "       'receiving_tds_r_avg_1_lag_1', 'receiving_tds_r_avg_3_lag_1',\n",
       "       'receiving_tds_r_avg_5_lag_1', 'receiving_tds_r_avg_8_lag_1',\n",
       "       'receiving_fumbles_lost_r_avg_1_lag_1',\n",
       "       'receiving_fumbles_lost_r_avg_3_lag_1',\n",
       "       'receiving_fumbles_lost_r_avg_5_lag_1',\n",
       "       'receiving_fumbles_lost_r_avg_8_lag_1',\n",
       "       'receiving_2pt_conversions_r_avg_1_lag_1',\n",
       "       'receiving_2pt_conversions_r_avg_3_lag_1',\n",
       "       'receiving_2pt_conversions_r_avg_5_lag_1',\n",
       "       'receiving_2pt_conversions_r_avg_8_lag_1',\n",
       "       'fantasy_points_r_avg_1_lag_1', 'fantasy_points_r_avg_3_lag_1',\n",
       "       'fantasy_points_r_avg_5_lag_1', 'fantasy_points_r_avg_8_lag_1',\n",
       "       'opp_team_dst_fp_r_avg_1_lag_1', 'opp_team_dst_fp_r_avg_3_lag_1',\n",
       "       'opp_team_dst_fp_r_avg_5_lag_1', 'opp_team_dst_fp_r_avg_8_lag_1',\n",
       "       'opp_team_dst_fp_rank_r_avg_1_lag_1',\n",
       "       'opp_team_dst_fp_rank_r_avg_3_lag_1',\n",
       "       'opp_team_dst_fp_rank_r_avg_5_lag_1',\n",
       "       'opp_team_dst_fp_rank_r_avg_8_lag_1', 'fantasy_points'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For copying and pasting into the columns_not_to_use variable below\n",
    "orig_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b8cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the X dataset in order to run the split\n",
    "columns_not_to_use = ['player_id'\n",
    "                    , 'player_name'\n",
    "                    , 'player_display_name'\n",
    "                    , 'position','position_group'\n",
    "                    , 'headshot_url'\n",
    "                    , 'season'\n",
    "                    , 'week'\n",
    "                    , 'season_type'\n",
    "                    , 'team'\n",
    "                    , 'opponent_team'\n",
    "                    , 'fantasy_points']\n",
    "columns_to_use = [col for col in orig_df.columns if col not in columns_not_to_use]\n",
    "X = orig_df[columns_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12691fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48775, 78) (48775, 78)\n",
      "(48775, 78) (48775, 78)\n",
      "(48775, 78) (48775, 78)\n",
      "(48775, 78) (48775, 78)\n",
      "(48776, 78) (48776, 78)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for idx, split in enumerate(kf.split(X)):\n",
    "    # Get file names\n",
    "    train_unnorm_name = f'{idx}_train_non-normalized.csv'\n",
    "    test_unnorm_name = f'{idx}_test_non-normalized.csv'\n",
    "    train_norm_name = f'{idx}_train_normalized.csv'\n",
    "    test_norm_name = f'{idx}_test_normalized.csv'\n",
    "    scaler_name = f'{idx}_scaler.pickle'\n",
    "    \n",
    "    # Get the indexes for the train and the test for the split\n",
    "    train_indexes = split[0]\n",
    "    test_indexes = split[1]\n",
    "    \n",
    "    # Pull only X columns\n",
    "    train_x_df = orig_df[columns_to_use].iloc[train_indexes] \n",
    "    test_x_df = orig_df[columns_to_use].iloc[test_indexes]\n",
    "\n",
    "    # Pull the rest of the columns (these will be more important for the normalized dataset)\n",
    "    train_y_df = orig_df[columns_not_to_use].iloc[train_indexes]\n",
    "    test_y_df = orig_df[columns_not_to_use].iloc[test_indexes]\n",
    "    \n",
    "    # Concatenate them together\n",
    "    train_unnorm_complete = pd.concat([train_y_df, train_x_df], axis=1) \n",
    "    test_unnorm_complete = pd.concat([test_y_df, test_x_df], axis=1) \n",
    "\n",
    "    # Write to file\n",
    "    train_unnorm_complete.to_csv(f'./datasets/{train_unnorm_name}')\n",
    "    test_unnorm_complete.to_csv(f'./datasets/{test_unnorm_name}')\n",
    "    \n",
    "    # Instantiate scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Run scaler on X columns for dataset\n",
    "    train_norm_x_df = pd.DataFrame(scaler.fit_transform(train_x_df), columns=columns_to_use)\n",
    "    test_norm_x_df = pd.DataFrame(scaler.transform(test_x_df), columns=columns_to_use)\n",
    "    \n",
    "    # Put non-X columns back into dataframe\n",
    "    train_norm_complete = pd.concat([train_y_df.reset_index(drop=True), train_norm_x_df], axis=1)\n",
    "    test_norm_complete = pd.concat([test_y_df.reset_index(drop=True), test_norm_x_df], axis=1) \n",
    " \n",
    "    # Write to file\n",
    "    train_norm_complete.to_csv(f'./datasets/{train_norm_name}')\n",
    "    test_norm_complete.to_csv(f'./datasets/{test_norm_name}')\n",
    "\n",
    "    # Write scaler to pickle for use later\n",
    "    with open(f'./datasets/{scaler_name}', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    # Check number of columns and number of records in dataset between normed and un-normed\n",
    "    print(train_unnorm_complete.shape, train_norm_complete.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625f483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
