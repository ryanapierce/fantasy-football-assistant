{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3af395",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA) for Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e84ad",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab21f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ad69a",
   "metadata": {},
   "source": [
    "### Load 5-Fold Cross-Validation Non-Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ab673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the KFold = 5 non-normalized data\n",
    "def load_kfold_data(fold):\n",
    "    train = pd.read_csv(f'../dataset_generators/datasets/{fold}_train_non-normalized.csv')\n",
    "    test = pd.read_csv(f'../dataset_generators/datasets/{fold}_test_non-normalized.csv')\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61056708",
   "metadata": {},
   "source": [
    "### Extract Each Fold and Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9de940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract each fold's data, apply PCA, and return transformed datasets\n",
    "def extract_each_fold_with_pca(n_components=0.95):\n",
    "    for fold in range(5):\n",
    "        train, test = load_kfold_data(fold)\n",
    "        X_train = train.iloc[:, 12:].drop(columns=['fantasy_points'])\n",
    "        y_train = train['fantasy_points']\n",
    "        X_test = test.iloc[:, 12:].drop(columns=['fantasy_points'])\n",
    "        y_test = test['fantasy_points']\n",
    "        \n",
    "        # Normalize data with StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "        yield X_train_pca, y_train, X_test_pca, y_test, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb7be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_list = list(extract_each_fold_with_pca())\n",
    "\n",
    "# Loop pca_list and store each PCA in it's own pickle file for later use\n",
    "import pickle\n",
    "for i, pca in enumerate(pca_list):\n",
    "    with open(f'../dataset_generators/datasets/{i}_pca.pkl', 'wb') as f:\n",
    "        pickle.dump(pca[4], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f83e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.76674383, -2.73706166, -0.81191576, ..., -0.02519278,\n",
       "         -0.41911951, -0.05732718],\n",
       "        [-1.01128538, -2.77333913, -0.86428403, ..., -0.04242404,\n",
       "          0.52887961, -0.04809846],\n",
       "        [ 3.56780352, -3.87825119,  0.36672879, ..., -0.34553452,\n",
       "         -0.00616753,  0.26097385],\n",
       "        ...,\n",
       "        [-0.29413727,  1.39709778, -2.69357012, ..., -0.04855384,\n",
       "          1.05162909, -0.05760293],\n",
       "        [-0.55400144,  0.71214974, -2.52019101, ..., -0.57712991,\n",
       "         -0.35096398,  0.06366663],\n",
       "        [-0.76263757,  0.17462775, -2.37871372, ..., -0.34804834,\n",
       "         -0.79895919,  0.04211365]]),\n",
       " 0        -0.20\n",
       " 1         7.04\n",
       " 2         9.40\n",
       " 3        15.38\n",
       " 4        16.22\n",
       "          ...  \n",
       " 48770     2.60\n",
       " 48771     8.70\n",
       " 48772     1.80\n",
       " 48773     2.00\n",
       " 48774     1.90\n",
       " Name: fantasy_points, Length: 48775, dtype: float64,\n",
       " array([[ 7.07586823e+00, -2.26950811e+00,  2.07720359e+00, ...,\n",
       "         -1.20596464e-01,  4.45936596e-01,  1.59148143e-01],\n",
       "        [ 1.46287713e+01, -3.25721522e+00,  4.45313698e+00, ...,\n",
       "          2.73202316e-01, -1.67643383e-01, -4.68199229e-01],\n",
       "        [ 1.49060358e+01, -3.32704438e+00,  4.18757426e+00, ...,\n",
       "          3.79905216e-02,  3.33974921e-01,  3.21295919e+00],\n",
       "        ...,\n",
       "        [-1.08700769e+00, -9.20096421e-01, -2.44476979e+00, ...,\n",
       "          2.32088644e-01,  3.33343374e-02, -4.06050283e-04],\n",
       "        [-1.18482995e+00, -1.03167778e+00, -2.22071995e+00, ...,\n",
       "         -2.23730001e-03, -2.44697415e-01,  2.91235495e-02],\n",
       "        [-8.86263715e-01, -2.87268894e-01, -2.42446911e+00, ...,\n",
       "         -4.61245392e-01, -2.80648345e-01,  2.32037078e-02]]),\n",
       " 0        13.32\n",
       " 1        28.62\n",
       " 2        29.60\n",
       " 3        15.46\n",
       " 4        28.08\n",
       "          ...  \n",
       " 12189     6.50\n",
       " 12190     5.00\n",
       " 12191     1.00\n",
       " 12192    11.50\n",
       " 12193     2.20\n",
       " Name: fantasy_points, Length: 12194, dtype: float64,\n",
       " PCA(n_components=0.95))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get each fold's PCA transformed data\n",
    "pca_data = list(extract_each_fold_with_pca())\n",
    "pca_data[3]  # Example to check the fourth fold's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c923a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pca_datasets(pca_data):\n",
    "    # Loop through each fold's PCA data and save to CSV\n",
    "    for fold, (X_train_pca, y_train, X_test_pca, y_test, _) in enumerate(pca_data):\n",
    "        # Load the original fold data to get the first 12 columns\n",
    "        train, test = load_kfold_data(fold)\n",
    "        \n",
    "        # Get first 12 columns from original data\n",
    "        first_12_cols_train = train.iloc[:, :12]\n",
    "        first_12_cols_test = test.iloc[:, :12]\n",
    "        \n",
    "        # Create dataframes with PCA features\n",
    "        pca_cols = [f'PC{i+1}' for i in range(X_train_pca.shape[1])]\n",
    "        train_pca_df = pd.DataFrame(X_train_pca, columns=pca_cols, index=y_train.index)\n",
    "        test_pca_df = pd.DataFrame(X_test_pca, columns=pca_cols, index=y_test.index)\n",
    "        \n",
    "        # Combine first 12 columns with PCA features and target\n",
    "        train_final = pd.concat([first_12_cols_train, train_pca_df], axis=1)\n",
    "        train_final['fantasy_points'] = y_train\n",
    "        \n",
    "        test_final = pd.concat([first_12_cols_test, test_pca_df], axis=1)\n",
    "        test_final['fantasy_points'] = y_test\n",
    "        \n",
    "        # Save to CSV\n",
    "        train_final.to_csv(f'../dataset_generators/datasets/{fold}_train_pca.csv', index=False)\n",
    "        test_final.to_csv(f'../dataset_generators/datasets/{fold}_test_pca.csv', index=False)\n",
    "        \n",
    "generate_pca_datasets(pca_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
